{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Authorship Attribution Training (Google Drive Integration)\n",
    "\n",
    "This notebook trains the BERT model with data stored in Google Drive, avoiding slow upload/download cycles.\n",
    "\n",
    "**Setup Requirements:**\n",
    "1. Upload `burney_colab_data.zip` to your Google Drive root\n",
    "2. Run this notebook in Google Colab with GPU enabled\n",
    "3. Model will save directly to Google Drive\n",
    "4. Download final model from Drive (faster than Colab direct download)\n",
    "\n",
    "**Time Estimate:** ~30 minutes on T4 GPU, ~15 minutes on V100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"‚úÖ Google Drive mounted at /content/drive/MyDrive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Data from Drive (First Time Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if data already exists in Drive\n",
    "drive_data_path = '/content/drive/MyDrive/burney_data'\n",
    "\n",
    "if os.path.exists(drive_data_path):\n",
    "    print(f\"‚úÖ Data already exists at {drive_data_path}\")\n",
    "    print(\"   Skipping extraction. Delete folder to re-extract.\")\n",
    "else:\n",
    "    print(\"üì¶ Extracting data from zip file...\")\n",
    "    zip_path = '/content/drive/MyDrive/burney_colab_data.zip'\n",
    "    \n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"‚ùå ERROR: {zip_path} not found!\")\n",
    "        print(\"   Please upload burney_colab_data.zip to your Google Drive root.\")\n",
    "    else:\n",
    "        # Extract to Drive (persists between sessions)\n",
    "        !unzip -q \"$zip_path\" -d /content/drive/MyDrive/burney_data\n",
    "        print(f\"‚úÖ Data extracted to {drive_data_path}\")\n",
    "        print(\"   This will persist between Colab sessions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets scikit-learn tqdm\n",
    "print(\"‚úÖ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# All paths point to Google Drive\n",
    "DRIVE_BASE = Path('/content/drive/MyDrive')\n",
    "DATA_DIR = DRIVE_BASE / 'burney_data' / 'data' / 'bert_data'\n",
    "OUTPUT_DIR = DRIVE_BASE / 'burney_models' / 'bert_authorship'\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Data location: {DATA_DIR}\")\n",
    "print(f\"üíæ Model will save to: {OUTPUT_DIR}\")\n",
    "print(\"\\n‚ö†Ô∏è  IMPORTANT: Model saves directly to Drive (no download needed!)\")\n",
    "print(\"   Access it from any device via Google Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"‚úÖ GPU available: {gpu_name}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå No GPU detected!\")\n",
    "    print(\"   Go to Runtime > Change runtime type > Select GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Data from Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import json\n",
    "\n",
    "# Load datasets from Drive\n",
    "print(\"üìñ Loading datasets from Google Drive...\")\n",
    "train_dataset = load_from_disk(str(DATA_DIR / 'chunked_datasets' / 'train'))\n",
    "val_dataset = load_from_disk(str(DATA_DIR / 'chunked_datasets' / 'validation'))\n",
    "test_dataset = load_from_disk(str(DATA_DIR / 'chunked_datasets' / 'test'))\n",
    "\n",
    "# Load label mapping\n",
    "with open(DATA_DIR / 'label_mapping.json', 'r') as f:\n",
    "    label_info = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Loaded datasets:\")\n",
    "print(f\"   Train: {len(train_dataset):,} samples\")\n",
    "print(f\"   Validation: {len(val_dataset):,} samples\")\n",
    "print(f\"   Test: {len(test_dataset):,} samples\")\n",
    "print(f\"\\nüìö Authors: {', '.join(label_info['author_to_id'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Model (Saves to Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "num_labels = len(label_info['author_to_id'])\n",
    "\n",
    "print(f\"ü§ñ Loading {model_name}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "# Training arguments - saves directly to Google Drive!\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(OUTPUT_DIR),  # ‚Üê Saves to Drive!\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    logging_dir=str(OUTPUT_DIR / 'logs'),\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1_weighted',\n",
    "    save_total_limit=2,  # Keep only best 2 checkpoints\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "# Metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    f1_weighted = f1_score(labels, predictions, average='weighted')\n",
    "    f1_macro = f1_score(labels, predictions, average='macro')\n",
    "    accuracy = (predictions == labels).mean()\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'f1_macro': f1_macro\n",
    "    }\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(\"\\nüèÉ Starting training...\")\n",
    "print(f\"   Model saves to: {OUTPUT_DIR}\")\n",
    "print(\"   This may take 30-45 minutes on T4 GPU\\n\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")\n",
    "print(f\"   Model saved to Google Drive: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß™ Evaluating on test set...\")\n",
    "\n",
    "# Evaluate\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Accuracy: {test_results['eval_accuracy']:.4f}\")\n",
    "print(f\"F1 (weighted): {test_results['eval_f1_weighted']:.4f}\")\n",
    "print(f\"F1 (macro): {test_results['eval_f1_macro']:.4f}\")\n",
    "\n",
    "# Detailed per-author results\n",
    "predictions = trainer.predict(test_dataset)\n",
    "pred_labels = np.argmax(predictions.predictions, axis=1)\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "id_to_author = {int(k): v for k, v in label_info['id_to_author'].items()}\n",
    "target_names = [id_to_author[i] for i in range(num_labels)]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PER-AUTHOR PERFORMANCE\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    pred_labels,\n",
    "    target_names=target_names,\n",
    "    digits=4\n",
    "))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Final Model to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model explicitly\n",
    "final_model_dir = OUTPUT_DIR / 'final'\n",
    "final_model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"üíæ Saving final model to {final_model_dir}...\")\n",
    "trainer.save_model(str(final_model_dir))\n",
    "tokenizer.save_pretrained(str(final_model_dir))\n",
    "\n",
    "print(\"\\n‚úÖ COMPLETE!\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"1. Model is saved in your Google Drive:\")\n",
    "print(f\"   {final_model_dir}\")\n",
    "print(\"\\n2. To use this model:\")\n",
    "print(\"   - Access via Google Drive on any device\")\n",
    "print(\"   - Download to local: Right-click folder > Download\")\n",
    "print(\"   - Or mount Drive in another Colab notebook\")\n",
    "print(\"\\n3. Files in the model directory:\")\n",
    "print(\"   - model.safetensors (~418 MB) - model weights\")\n",
    "print(\"   - config.json - model configuration\")\n",
    "print(\"   - tokenizer files - for text processing\")\n",
    "print(\"\\n4. To test on anonymous works:\")\n",
    "print(\"   - Upload test_anonymous_attribution.py to Colab\")\n",
    "print(\"   - Point it to this Drive model directory\")\n",
    "print(\"   - Run tests directly in Colab (no download!)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Download Model to Local (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this if you want to download via Colab\n",
    "# (Usually faster to download directly from Google Drive)\n",
    "\n",
    "# Uncomment to create zip and download:\n",
    "# !zip -r final_model.zip \"/content/drive/MyDrive/burney_models/bert_authorship/final\"\n",
    "# from google.colab import files\n",
    "# files.download('final_model.zip')\n",
    "\n",
    "print(\"‚ö†Ô∏è  Recommendation: Download from Google Drive instead\")\n",
    "print(\"   It's faster and doesn't count against Colab usage limits\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
